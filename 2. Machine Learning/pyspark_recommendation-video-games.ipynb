{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:37:35 WARN Utils: Your hostname, Sophies-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.6 instead (on interface en0)\n",
      "25/01/27 10:37:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/27 10:37:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.6:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>app recommendation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10ae7cf90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Init sparkcontext\n",
    "sc = SparkContext(master=\"local\", appName=\"app recommendation\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession(sc)\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pyspark.sql.types as t\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Creating ALS model and fitting data\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
      "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|0700099867|[8, 12]|    1.0|Installing the ga...| 07 9, 2012|A2HD75EMZR8QLN|                 123|Pay to unlock con...|    1341792000|\n",
      "|0700099867| [0, 0]|    4.0|If you like rally...|06 30, 2013|A3UR8NLLY1ZHCX|Alejandro Henao \"...|     Good rally game|    1372550400|\n",
      "|0700099867| [0, 0]|    1.0|1st shipment rece...|06 28, 2014|A1INA0F5CWW3J4|Amazon Shopper \"M...|           Wrong key|    1403913600|\n",
      "|0700099867|[7, 10]|    3.0|I got this versio...|09 14, 2011|A1DLMTOTHQ4AST|            ampgreen|awesome game, if ...|    1315958400|\n",
      "|0700099867| [2, 2]|    4.0|I had Dirt 2 on X...|06 14, 2011|A361M14PU2GUEG|Angry Ryan \"Ryan ...|              DIRT 3|    1308009600|\n",
      "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('Data/reviews_Video_Games_5.json.gz')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+\n",
      "|      asin|    reviewerID|overall|\n",
      "+----------+--------------+-------+\n",
      "|0700099867|A2HD75EMZR8QLN|    1.0|\n",
      "|0700099867|A3UR8NLLY1ZHCX|    4.0|\n",
      "|0700099867|A1INA0F5CWW3J4|    1.0|\n",
      "|0700099867|A1DLMTOTHQ4AST|    3.0|\n",
      "|0700099867|A361M14PU2GUEG|    4.0|\n",
      "+----------+--------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = df.select('asin', 'reviewerID', 'overall')\n",
    "final_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- overall: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------------+------------------+\n",
      "|summary|               asin|          reviewerID|           overall|\n",
      "+-------+-------------------+--------------------+------------------+\n",
      "|  count|             231780|              231780|            231780|\n",
      "|   mean|7.198617864286957E9|                NULL| 4.086396582966606|\n",
      "| stddev|3.628023820739709E9|                NULL|1.2023296087789057|\n",
      "|    min|         0700099867|A00263941WP7WCIL7...|               1.0|\n",
      "|    max|         B00KHECZXO|       AZZTC2OYVNE2Q|               5.0|\n",
      "+-------+-------------------+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asin 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewerID 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check null values\n",
    "for col in final_data.columns:\n",
    "    print(col, final_data.where(final_data[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is no NA values in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated values (if any)\n",
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:37:48 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the number of unique users in the dataset\n",
    "users = final_data.select('reviewerID').distinct().count()\n",
    "# Count the number of unique products in the dataset\n",
    "products = final_data.select('asin').distinct().count()\n",
    "# Count total number of user–product interactions (ratings/reviews)\n",
    "numerator = final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231780"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "24303"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10672"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the interaction count along with the number of users and products\n",
    "display(numerator, users, products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259361616"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of ratings matrix could contain if no empty cellers\n",
    "denominator = users * products \n",
    "denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity:  0.9991063442479476\n"
     ]
    }
   ],
   "source": [
    "# Compute sparsity of the user–item matrix\n",
    "sparsity = 1 - (numerator*1.0/ denominator)\n",
    "print('sparsity: ', sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create an indexer\n",
    "indexer = StringIndexer(inputCol='asin',\n",
    "                        outputCol='asin_idx')\n",
    "\n",
    "# Indexer identifies categories in the data\n",
    "indexer_model = indexer.fit(final_data) \n",
    "\n",
    "# Indexer creates a new column with numeric index values\n",
    "data_indexed = indexer_model.transform(final_data)\n",
    "\n",
    "# Repeat the process for the other categorical feature\n",
    "indexer1 = StringIndexer(inputCol='reviewerID',\n",
    "                         outputCol='reviewerID_idx')\n",
    "indexer1_model = indexer1.fit(data_indexed)\n",
    "data_indexed = indexer1_model.transform(data_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:37:55 WARN DAGScheduler: Broadcasting large task binary with size 1434.3 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+--------+--------------+\n",
      "|      asin|    reviewerID|overall|asin_idx|reviewerID_idx|\n",
      "+----------+--------------+-------+--------+--------------+\n",
      "|0700099867|A2HD75EMZR8QLN|    1.0|  2269.0|       14157.0|\n",
      "|0700099867|A3UR8NLLY1ZHCX|    4.0|  2269.0|       22489.0|\n",
      "|0700099867|A1INA0F5CWW3J4|    1.0|  2269.0|        7934.0|\n",
      "|0700099867|A1DLMTOTHQ4AST|    3.0|  2269.0|        7852.0|\n",
      "|0700099867|A361M14PU2GUEG|    4.0|  2269.0|         847.0|\n",
      "+----------+--------------+-------+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows\n",
    "data_indexed.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin_idx</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID_idx</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "asin            0\n",
       "reviewerID      0\n",
       "overall         0\n",
       "asin_idx        0\n",
       "reviewerID_idx  0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check NA values again\n",
    "data_indexed.select([f.count(f.when(f.col(c).isNull(), c)).alias(c) for c in\n",
    "           data_indexed.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller dataset so we will use 0.8 / 0.2\n",
    "(training, test) = data_indexed.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:37:57 WARN DAGScheduler: Broadcasting large task binary with size 1462.2 KiB\n",
      "25/01/27 10:37:59 WARN DAGScheduler: Broadcasting large task binary with size 1464.5 KiB\n",
      "25/01/27 10:38:01 WARN DAGScheduler: Broadcasting large task binary with size 1466.0 KiB\n",
      "25/01/27 10:38:01 WARN DAGScheduler: Broadcasting large task binary with size 1467.3 KiB\n",
      "25/01/27 10:38:01 WARN DAGScheduler: Broadcasting large task binary with size 1466.3 KiB\n",
      "25/01/27 10:38:02 WARN DAGScheduler: Broadcasting large task binary with size 1467.6 KiB\n",
      "25/01/27 10:38:02 WARN DAGScheduler: Broadcasting large task binary with size 1468.4 KiB\n",
      "25/01/27 10:38:02 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/01/27 10:38:02 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "25/01/27 10:38:02 WARN DAGScheduler: Broadcasting large task binary with size 1471.5 KiB\n",
      "25/01/27 10:38:03 WARN DAGScheduler: Broadcasting large task binary with size 1472.9 KiB\n",
      "25/01/27 10:38:03 WARN DAGScheduler: Broadcasting large task binary with size 1474.3 KiB\n",
      "25/01/27 10:38:04 WARN DAGScheduler: Broadcasting large task binary with size 1475.7 KiB\n",
      "25/01/27 10:38:04 WARN DAGScheduler: Broadcasting large task binary with size 1477.0 KiB\n",
      "25/01/27 10:38:04 WARN DAGScheduler: Broadcasting large task binary with size 1478.4 KiB\n",
      "25/01/27 10:38:05 WARN DAGScheduler: Broadcasting large task binary with size 1479.8 KiB\n",
      "25/01/27 10:38:05 WARN DAGScheduler: Broadcasting large task binary with size 1481.2 KiB\n",
      "25/01/27 10:38:05 WARN DAGScheduler: Broadcasting large task binary with size 1482.6 KiB\n",
      "25/01/27 10:38:06 WARN DAGScheduler: Broadcasting large task binary with size 1484.0 KiB\n",
      "25/01/27 10:38:06 WARN DAGScheduler: Broadcasting large task binary with size 1485.4 KiB\n",
      "25/01/27 10:38:06 WARN DAGScheduler: Broadcasting large task binary with size 1486.7 KiB\n",
      "25/01/27 10:38:07 WARN DAGScheduler: Broadcasting large task binary with size 1488.1 KiB\n",
      "25/01/27 10:38:07 WARN DAGScheduler: Broadcasting large task binary with size 1489.5 KiB\n",
      "25/01/27 10:38:07 WARN DAGScheduler: Broadcasting large task binary with size 1490.9 KiB\n",
      "25/01/27 10:38:08 WARN DAGScheduler: Broadcasting large task binary with size 1492.3 KiB\n",
      "25/01/27 10:38:08 WARN DAGScheduler: Broadcasting large task binary with size 1493.7 KiB\n",
      "25/01/27 10:38:08 WARN DAGScheduler: Broadcasting large task binary with size 1495.1 KiB\n",
      "25/01/27 10:38:09 WARN DAGScheduler: Broadcasting large task binary with size 1496.5 KiB\n",
      "25/01/27 10:38:09 WARN DAGScheduler: Broadcasting large task binary with size 1498.4 KiB\n",
      "25/01/27 10:38:09 WARN DAGScheduler: Broadcasting large task binary with size 1497.0 KiB\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ALS (Alternating Least Squares) recommendation model\n",
    "# - maxIter: number of optimization iterations\n",
    "# - regParam: regularization parameter to prevent overfitting\n",
    "# - rank: number of latent factors\n",
    "# - userCol / itemCol: indexed user and item columns\n",
    "# - ratingCol: column containing rating values\n",
    "# - coldStartStrategy=\"drop\": remove rows with unseen users/items during prediction\n",
    "# - nonnegative=True: enforce non-negative latent factors\n",
    "als = ALS(maxIter=10,\n",
    "          regParam=0.1,\n",
    "          rank = 15,\n",
    "          userCol=\"reviewerID_idx\",\n",
    "          itemCol=\"asin_idx\",\n",
    "          ratingCol=\"overall\",\n",
    "          coldStartStrategy=\"drop\",\n",
    "          nonnegative=True)\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:38:10 WARN DAGScheduler: Broadcasting large task binary with size 1447.0 KiB\n",
      "25/01/27 10:38:10 WARN DAGScheduler: Broadcasting large task binary with size 1506.4 KiB\n",
      "25/01/27 10:38:10 WARN DAGScheduler: Broadcasting large task binary with size 1505.1 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+--------+--------------+----------+\n",
      "|      asin|    reviewerID|overall|asin_idx|reviewerID_idx|prediction|\n",
      "+----------+--------------+-------+--------+--------------+----------+\n",
      "|B00000DMAR|A1QHGON6QDTX2K|    5.0|  1621.0|       13285.0| 3.7676222|\n",
      "|B00000DMAX|A2AV2TR28DGSGC|    5.0|   621.0|        1645.0|  3.969711|\n",
      "|B00000F1GM|A2AV2TR28DGSGC|    5.0|   290.0|        1645.0| 3.4763653|\n",
      "|B00000I1BY|A313Y959E605NE|    1.0|  1148.0|        4818.0| 3.8026812|\n",
      "|B00000K10O|A313Y959E605NE|    4.0|  4417.0|        4818.0| 2.5002816|\n",
      "+----------+--------------+-------+--------+--------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:38:12 WARN DAGScheduler: Broadcasting large task binary with size 1446.3 KiB\n",
      "25/01/27 10:38:12 WARN DAGScheduler: Broadcasting large task binary with size 1506.4 KiB\n",
      "25/01/27 10:38:12 WARN DAGScheduler: Broadcasting large task binary with size 1505.1 KiB\n",
      "25/01/27 10:38:15 WARN DAGScheduler: Broadcasting large task binary with size 1554.1 KiB\n"
     ]
    }
   ],
   "source": [
    "# Create a RegressionEvaluator to compute the RMSE (Root Mean Squared Error)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                labelCol=\"overall\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "# Evaluate the predictions and calculate RMSE.\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.2366237557457707\n"
     ]
    }
   ],
   "source": [
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an RMSE of 1.22, the error is relatively low. However, considering the rating scale ranges from 1 to 5, a gap of 1 to 2 can be considered significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 5 recommendations which have highest rating.\n",
    "user_recs = model.recommendForAllUsers(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:38:15 WARN DAGScheduler: Broadcasting large task binary with size 1553.6 KiB\n",
      "25/01/27 10:38:26 WARN DAGScheduler: Broadcasting large task binary with size 1546.9 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------------------------------------------------------------------------------+\n",
      "|reviewerID_idx|recommendations                                                                                |\n",
      "+--------------+-----------------------------------------------------------------------------------------------+\n",
      "|0             |[{9197, 5.780767}, {10136, 5.7159014}, {2587, 5.702335}, {7944, 5.6433306}, {10028, 5.623686}] |\n",
      "|1             |[{7944, 5.403418}, {7425, 5.371918}, {6024, 5.297246}, {6067, 5.2707233}, {4108, 5.2683897}]   |\n",
      "|2             |[{2931, 5.1611834}, {6067, 5.076249}, {6024, 5.0754766}, {10460, 4.9933643}, {10286, 4.987646}]|\n",
      "|3             |[{4651, 5.407189}, {3136, 5.301354}, {7944, 5.2374344}, {3964, 5.181002}, {6067, 5.139053}]    |\n",
      "|4             |[{7944, 5.4843287}, {10434, 5.4207206}, {6067, 5.399769}, {7425, 5.3823752}, {6024, 5.3648324}]|\n",
      "|5             |[{6067, 6.2858877}, {2931, 6.148175}, {6024, 6.102043}, {9084, 6.075832}, {6008, 6.027116}]    |\n",
      "|6             |[{4651, 6.366014}, {3136, 5.9672503}, {9089, 5.8989515}, {10662, 5.8267035}, {3964, 5.80523}]  |\n",
      "|7             |[{7509, 5.3638835}, {3880, 5.2723613}, {7947, 5.14127}, {4768, 5.1395497}, {261, 5.088324}]    |\n",
      "|8             |[{6067, 5.776828}, {6024, 5.709651}, {4651, 5.6591644}, {5114, 5.6488113}, {2587, 5.6484017}]  |\n",
      "|9             |[{2261, 5.0778604}, {2931, 5.004289}, {5591, 4.83789}, {9361, 4.800103}, {8272, 4.7942142}]    |\n",
      "+--------------+-----------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user_recs.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend for users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " (A29KT7UP7DLM1J, A1WGVOVABHFDF3, A3DIS5O83SQJWW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a mapping table of unique reviewer index → original reviewer ID\n",
    "df_reviewer_reviewer_id = data_indexed.select('reviewerID_idx', 'reviewerID').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:38:26 WARN DAGScheduler: Broadcasting large task binary with size 1124.3 KiB\n",
      "25/01/27 10:38:28 WARN DAGScheduler: Broadcasting large task binary with size 1132.6 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24303"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviewer_reviewer_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:38:28 WARN DAGScheduler: Broadcasting large task binary with size 1124.3 KiB\n",
      "[Stage 215:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|reviewerID_idx|    reviewerID|\n",
      "+--------------+--------------+\n",
      "|       20806.0|A2ZYJOZO6BPV6K|\n",
      "|         735.0|A3TQTYD0D6AUO3|\n",
      "|        2580.0|A2QVKLB1VT903K|\n",
      "|        9117.0|A3OMBKL5EOHA36|\n",
      "|        2945.0|A2NWQA506BES77|\n",
      "+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:38:29 WARN DAGScheduler: Broadcasting large task binary with size 1129.2 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_reviewer_reviewer_id.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the user recommendations with the mapping table\n",
    "new_user_recs = user_recs.join(df_reviewer_reviewer_id, on=['reviewerID_idx'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:38:29 WARN DAGScheduler: Broadcasting large task binary with size 1553.6 KiB\n",
      "25/01/27 10:38:29 WARN DAGScheduler: Broadcasting large task binary with size 1124.3 KiB\n",
      "25/01/27 10:38:39 WARN DAGScheduler: Broadcasting large task binary with size 1548.9 KiB\n",
      "[Stage 242:>                (0 + 1) / 1][Stage 267:>                (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------------------------------------------------------------------------------+--------------+\n",
      "|reviewerID_idx|recommendations                                                                                |reviewerID    |\n",
      "+--------------+-----------------------------------------------------------------------------------------------+--------------+\n",
      "|8             |[{6067, 5.776828}, {6024, 5.709651}, {4651, 5.6591644}, {5114, 5.6488113}, {2587, 5.6484017}]  |A1AISPOIIHTHXX|\n",
      "|0             |[{9197, 5.780767}, {10136, 5.7159014}, {2587, 5.702335}, {7944, 5.6433306}, {10028, 5.623686}] |A3V6Z4RCDGRC44|\n",
      "|7             |[{7509, 5.3638835}, {3880, 5.2723613}, {7947, 5.14127}, {4768, 5.1395497}, {261, 5.088324}]    |A20DZX38KRBIT8|\n",
      "|1             |[{7944, 5.403418}, {7425, 5.371918}, {6024, 5.297246}, {6067, 5.2707233}, {4108, 5.2683897}]   |AJKWF4W7QD4NS |\n",
      "|4             |[{7944, 5.4843287}, {10434, 5.4207206}, {6067, 5.399769}, {7425, 5.3823752}, {6024, 5.3648324}]|A29BQ6B90Y1R5F|\n",
      "|3             |[{4651, 5.407189}, {3136, 5.301354}, {7944, 5.2374344}, {3964, 5.181002}, {6067, 5.139053}]    |A2QHS1ZCIQOL7E|\n",
      "|2             |[{2931, 5.1611834}, {6067, 5.076249}, {6024, 5.0754766}, {10460, 4.9933643}, {10286, 4.987646}]|A3W4D8XOGLWUN5|\n",
      "|10            |[{4651, 6.016482}, {7824, 5.9717755}, {3248, 5.900679}, {9192, 5.8333807}, {5925, 5.7317486}]  |A3GKMQFL05Z79K|\n",
      "|6             |[{4651, 6.366014}, {3136, 5.9672503}, {9089, 5.8989515}, {10662, 5.8267035}, {3964, 5.80523}]  |A2TCG2HV1VJP6V|\n",
      "|5             |[{6067, 6.2858877}, {2931, 6.148175}, {6024, 6.102043}, {9084, 6.075832}, {6008, 6.027116}]    |AFV2584U13XP3 |\n",
      "+--------------+-----------------------------------------------------------------------------------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:38:41 WARN DAGScheduler: Broadcasting large task binary with size 1128.4 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "new_user_recs.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/27 10:38:41 WARN DAGScheduler: Broadcasting large task binary with size 1553.6 KiB\n",
      "25/01/27 10:38:41 WARN DAGScheduler: Broadcasting large task binary with size 1126.6 KiB\n",
      "25/01/27 10:38:50 WARN DAGScheduler: Broadcasting large task binary with size 1548.3 KiB\n",
      "25/01/27 10:38:52 WARN DAGScheduler: Broadcasting large task binary with size 1129.6 KiB\n",
      "[Stage 345:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------------------------------------------------------------------------------+--------------+\n",
      "|reviewerID_idx|recommendations                                                                                |reviewerID    |\n",
      "+--------------+-----------------------------------------------------------------------------------------------+--------------+\n",
      "|6623          |[{4651, 6.1226444}, {7824, 6.078095}, {10434, 6.0312996}, {6067, 5.9631543}, {3831, 5.947102}] |A1WGVOVABHFDF3|\n",
      "|4622          |[{9398, 5.3144712}, {7618, 5.2516456}, {2931, 5.1145115}, {8935, 5.107025}, {10155, 5.0728745}]|A29KT7UP7DLM1J|\n",
      "|780           |[{4651, 5.919368}, {9156, 5.4918456}, {2371, 5.466826}, {10662, 5.4606595}, {5916, 5.3917036}] |A3DIS5O83SQJWW|\n",
      "+--------------+-----------------------------------------------------------------------------------------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Recommendation for specific users'\n",
    "reviewerID = ['A29KT7UP7DLM1J', 'A1WGVOVABHFDF3', 'A3DIS5O83SQJWW']\n",
    "find_user_rec = new_user_recs.filter(new_user_recs['reviewerID'].isin(reviewerID))\n",
    "find_user_rec.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
